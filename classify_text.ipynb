{
 "metadata": {
  "name": "",
  "signature": "sha256:2404e0fdc32ce1da7f3aed268845824cbc43e02fb0457ff46a3f7d271d5020b4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classify text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.util import ngrams\n",
      "\n",
      "def get_features(word):\n",
      "    word = word.lower()\n",
      "    \n",
      "    feature = {'word('+ word + ')': True}\n",
      "    feature['sufix1'] =  word[-1:]\n",
      "    \n",
      "    \n",
      "    for ngram in  ngrams(word, 2):\n",
      "        feature['bigram' + str(ngram) + ''] = True\n",
      "    \n",
      "        \n",
      "    for ngram in  ngrams(word, 3):\n",
      "        feature['trigram' + str(ngram) + ''] = True\n",
      "    \n",
      "    \n",
      "    return feature\n",
      "        \n",
      "def get_features_from_file(file):\n",
      "\n",
      "    lines = [line.rstrip() for line in open(file)]\n",
      "    \n",
      "    features = []\n",
      "    \n",
      "    for word in lines:\n",
      "        \n",
      "        features.append(get_features(word))\n",
      "    \n",
      "    return features\n",
      "\n",
      "def get_features_from_sentenece(sentence):\n",
      "    features = {}\n",
      "    for word in sentence.split(' '):\n",
      "        features.update(get_features(word))\n",
      "    return features\n",
      "        \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featuresets_de = [(f, 'de') for f in get_features_from_file('data/top1000de.txt')]\n",
      "featuresets_en = [(f, 'en') for f in get_features_from_file('data/top1000en.txt')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "\n",
      "random.shuffle(featuresets_de)\n",
      "random.shuffle(featuresets_en)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('German features', len(featuresets_de))\n",
      "print('English features', len(featuresets_de))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('German features', 1000)\n",
        "('English features', 1000)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(featuresets_de[0])\n",
      "print(featuresets_en[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "({\"trigram('d', 'e', 'r')\": True, \"bigram('r', ' ')\": True, \"trigram('r', ' ', 'w')\": True, \"trigram('e', 'd', 'e')\": True, \"bigram('m', 'e')\": True, \"trigram(' ', 'w', 'i')\": True, \"bigram('m', 'm')\": True, \"trigram('e', 'r', ' ')\": True, \"trigram('m', 'e', 'r')\": True, \"bigram(' ', 'w')\": True, \"bigram('i', 'e')\": True, \"trigram('m', 'm', 'e')\": True, \"trigram('i', 'm', 'm')\": True, 'word(immer wieder)': True, 'sufix1': 'r', \"bigram('e', 'r')\": True, \"bigram('w', 'i')\": True, \"trigram('i', 'e', 'd')\": True, \"trigram('w', 'i', 'e')\": True, \"bigram('i', 'm')\": True, \"bigram('d', 'e')\": True, \"bigram('e', 'd')\": True}, 'de')\n",
        "({'word(be)': True, 'sufix1': 'e', \"bigram('b', 'e')\": True}, 'en')\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_feats, test_feats = featuresets_de[200:] + featuresets_en[200:], featuresets_de[:200] + featuresets_en[:200]\n",
      "classifier = nltk.NaiveBayesClassifier.train(train_feats)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifier, test_feats))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.8425\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(classifier.classify(get_features_from_sentenece('Mein Name ist Hugo')))\n",
      "print(classifier.classify(get_features_from_sentenece('My name is Hugo')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "de\n",
        "en\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.show_most_informative_features(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "  trigram('i', 'c', 'h') = True               de : en     =     28.3 : 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        bigram('e', 'a') = True               en : de     =     23.7 : 1.0\n",
        "  trigram('s', 'c', 'h') = True               de : en     =     23.0 : 1.0\n",
        "  trigram('c', 'h', 'e') = True               de : en     =     20.3 : 1.0\n",
        "  trigram('e', 'i', 'n') = True               de : en     =     19.7 : 1.0\n",
        "        bigram('e', 'i') = True               de : en     =     18.8 : 1.0\n",
        "  trigram('e', 'i', 't') = True               de : en     =     18.3 : 1.0\n",
        "        bigram('t', 'h') = True               en : de     =     17.4 : 1.0\n",
        "        bigram('h', 'r') = True               de : en     =     16.3 : 1.0\n",
        "        bigram('e', 'h') = True               de : en     =     15.7 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import collections\n",
      "import nltk.metrics\n",
      "\n",
      "refsets = collections.defaultdict(set)\n",
      "testsets = collections.defaultdict(set)\n",
      " \n",
      "for i, (feats, label) in enumerate(test_feats):\n",
      "    refsets[label].add(i)\n",
      "    observed = classifier.classify(feats)\n",
      "    testsets[observed].add(i)\n",
      " \n",
      "print 'DE precision:', nltk.metrics.precision(refsets['de'], testsets['de'])\n",
      "print 'DE recall:', nltk.metrics.recall(refsets['de'], testsets['de'])\n",
      "print 'DE F-measure:', nltk.metrics.f_measure(refsets['de'], testsets['de'])\n",
      "print 'EN precision:', nltk.metrics.precision(refsets['en'], testsets['en'])\n",
      "print 'EN recall:', nltk.metrics.recall(refsets['en'], testsets['en'])\n",
      "print 'EN F-measure:', nltk.metrics.f_measure(refsets['en'], testsets['en'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DE precision: 0.8407960199\n",
        "DE recall: 0.845\n",
        "DE F-measure: 0.84289276808\n",
        "EN precision: 0.844221105528\n",
        "EN recall: 0.84\n",
        "EN F-measure: 0.842105263158\n"
       ]
      }
     ],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}